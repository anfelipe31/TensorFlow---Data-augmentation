{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Exercise_2_Cats_vs_Dogs_using_augmentation_Question-FINAL (2).json",
      "provenance": [],
      "collapsed_sections": []
    },
    "coursera": {
      "course_slug": "convolutional-neural-networks-tensorflow",
      "graded_item_id": "uAPOR",
      "launcher_item_id": "e9lTb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpEsqXYcySfi"
      },
      "source": [
        "This exercise is one of the required activities in the course of Convolutional neural networks in TensorFlow in Coursera provided by DeepLearning.AI.\n",
        "\n",
        "Keywords:\n",
        "\n",
        "Deep learning,\n",
        "Neural networks,\n",
        "TensorFlow,\n",
        "Image data generator,\n",
        "Data augmentation,\n",
        "Image classification,\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn-6c02VmqiN"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "from os import getcwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sd9dQWa23aj"
      },
      "source": [
        "# This code block unzips the full Cats-v-Dogs dataset to /tmp\n",
        "# which will create a tmp/PetImages directory containing subdirectories\n",
        "# called 'Cat' and 'Dog' (that's how the original researchers structured it)\n",
        "path_cats_and_dogs = f\"{getcwd()}/../tmp2/cats-and-dogs.zip\"\n",
        "shutil.rmtree('/tmp')\n",
        "\n",
        "local_zip = path_cats_and_dogs\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi3yD62a6X3S",
        "outputId": "76a8c2d5-5869-471e-b3ef-0c65c34f701e"
      },
      "source": [
        "print(len(os.listdir('/tmp/PetImages/Cat/')))\n",
        "print(len(os.listdir('/tmp/PetImages/Dog/')))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1500\n",
            "1500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-QkLjxpmyK2"
      },
      "source": [
        "# Use os.mkdir to create directories for training and testing for each class\n",
        "\n",
        "try:\n",
        "    os.mkdir('/tmp/cats-v-dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training/dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\n",
        "except OSError:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvSODo0f9LaU"
      },
      "source": [
        "#This fucntion splits the data in training and testing\n",
        "\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    list = []\n",
        "    \n",
        "    for element in os.listdir(SOURCE):\n",
        "        path = SOURCE + element\n",
        "        if(os.path.getsize(path)>0): # Only takes files which size is bigger that cero\n",
        "            list.append(element)\n",
        "            \n",
        "        else:\n",
        "            continue\n",
        "            \n",
        "    \n",
        "    n_pictures = len(list)\n",
        "    training_length = int(n_pictures*SPLIT_SIZE)\n",
        "    shuffle_list = random.sample(list, len(list))\n",
        "    training_data = shuffle_list[:training_length]\n",
        "    testing_data = shuffle_list[training_length:]\n",
        "    \n",
        "    for picture in training_data:\n",
        "        temp_training = SOURCE + picture\n",
        "        trianing = TRAINING + picture\n",
        "        copyfile(temp_training, trianing)\n",
        "        \n",
        "    for picture in testing_data:\n",
        "        temp_testing = SOURCE + picture\n",
        "        testing = TESTING + picture\n",
        "        copyfile(temp_testing, testing)\n",
        "    \n",
        "\n",
        "\n",
        "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
        "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n",
        "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n",
        "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
        "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n",
        "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n",
        "\n",
        "split_size = .9\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luthalB76ufC",
        "outputId": "c21202e3-4d10-47cb-f1ea-f7d779d1fe10"
      },
      "source": [
        "#Verify amount of items in each folder\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1350\n",
            "1350\n",
            "150\n",
            "150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BQrav4anTmj"
      },
      "source": [
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', input_shape = (300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "])\n",
        "\n",
        "model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlNjoJ5D61N6",
        "outputId": "679ab76d-80d8-45ec-ee44-7e5f8b7f0319"
      },
      "source": [
        "#Use augmentation on the training dataset\n",
        "TRAINING_DIR = '/tmp/cats-v-dogs/training'\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1/255,\n",
        "    rotation_range = 40,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest')\n",
        "\n",
        "#Train the model with the augmented training dataset\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "          '/tmp/cats-v-dogs/training',\n",
        "          target_size = (300,300),\n",
        "          batch_size = 10,\n",
        "          class_mode = 'binary'\n",
        ")\n",
        "\n",
        "#Testing the model\n",
        "VALIDATION_DIR = '/tmp/cats-v-dogs/testing'\n",
        "validation_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "          VALIDATION_DIR,\n",
        "          target_size = (300,300),\n",
        "          batch_size = 10,\n",
        "          class_mode = 'binary'\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2700 images belonging to 2 classes.\n",
            "Found 300 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyS4n53w7DxC"
      },
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              epochs=2,\n",
        "                              verbose=1,\n",
        "                              validation_data=validation_generator)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWZrJN4-65RC"
      },
      "source": [
        "# PLOT LOSS AND ACCURACY\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "\n",
        "\n",
        "plt.title('Training and validation loss')\n",
        "\n",
        "# Desired output. Charts with training and validation metrics. No crash :)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}